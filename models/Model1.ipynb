{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34631de7",
   "metadata": {},
   "source": [
    "This first model buidls classifiers for each of the prolific authors with `id` equal to `0,...,99` by using a 'vectorised' representation of the text. \n",
    "\n",
    "The idea behind this model is to capture the vocabularly of each author, and the resulting high dimensional feature space should result in near-linear separability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2cc50a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from typing import List\n",
    "\n",
    "RANDOM_STATE = 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b604e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_set(path: str):\n",
    "    \"\"\"\n",
    "    loads data set located at path and returns as pandas data frame\n",
    "    \"\"\"\n",
    "    with open(path) as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    print(f\"loaded {len(data)} instances\")\n",
    "    data = pd.json_normalize(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23688c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "\n",
    "def pre_processing(df: pd.DataFrame, train=True):\n",
    "    \"\"\"\n",
    "    performs initial preprocessing to base data frame\n",
    "    \"\"\"\n",
    "    if train:\n",
    "        # preprocessing for authors\n",
    "        df[\"target authors\"] = df[\"authors\"].apply(lambda x: filter_authors(x))\n",
    "        df[\"coauthors\"]      = df[\"authors\"].apply(lambda x: filter_authors(x, prolifics=False))\n",
    "        df[\"has target\"]     = df[\"target authors\"].apply(lambda x: len(x)>0)\n",
    "        df = df[df[\"has target\"] == True]\n",
    "        df = df.drop([\"authors\", \"has target\"], axis=1)\n",
    "    \n",
    "    # preprocessing for text\n",
    "    df[\"abstract\"] = df[\"abstract\"].apply(lambda x: text_to_vector(x))\n",
    "    df[\"title\"]    = df[\"title\"].apply(lambda x: text_to_vector(x))\n",
    "    df[\"text\"]     = df[\"title\"] + df[\"abstract\"]\n",
    "    text_df = pd.DataFrame(df.text.tolist(), index=df.index)\n",
    "    \n",
    "    # dropping irrelivent columns\n",
    "    df = df.drop([\"abstract\", \"title\", \"venue\", \"coauthors\", \"text\", \"year\"], axis=1)\n",
    "    df = pd.concat([df, text_df], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad6e280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature transformations\n",
    "\n",
    "def filter_authors(authors: List[int], prolifics=True):\n",
    "    if prolifics:\n",
    "        prolifics = filter(lambda x: x < 100, authors)\n",
    "        return list(prolifics)\n",
    "    else:\n",
    "        coauthors = filter(lambda x: x>=100, authors)\n",
    "        return list(coauthors)\n",
    "    \n",
    "    \n",
    "def text_to_vector(text: List[int]):\n",
    "    \"\"\"\n",
    "    Converts text to sparse matrix representation\n",
    "    text: List of integers between 1, 4999\n",
    "    \"\"\"\n",
    "    word_vec = np.zeros(5000, dtype=int)\n",
    "    for word in text:\n",
    "        word_vec[word] += 1\n",
    "    return word_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1b03eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "def train_classifier(author: int, df: pd.DataFrame, debug=False):\n",
    "    \"\"\"\n",
    "    Trains a classifier for author i. Assumes text-vectorisaiton has occured.\n",
    "    \n",
    "    Model Features:\n",
    "    text vectorisation\n",
    "    \"\"\"\n",
    "    # create copy and set up label\n",
    "    df = df.copy(deep=True)\n",
    "    df[\"label\"] = df[\"target authors\"].apply(lambda x: 1 if author in x else 0)\n",
    "    \n",
    "    # split up positive and negative instances so as to ensure a balanced training set \n",
    "    # if we don't do this, we end up with a very imbalanced training set \n",
    "    # however, if we don't include enough negative samples, we tend to \"overclassify\". \n",
    "    # we can tune out performance with the below 'neg sample factor'\n",
    "    \n",
    "    neg_sample_factor = 10\n",
    "    \n",
    "    pos = df[df['label'] == 1] \n",
    "    neg = df[df['label'] == 0]\n",
    "    \n",
    "    n_pos_samples = pos.shape[0]\n",
    "    n_tot_samples = df.shape[0]\n",
    "    \n",
    "    # takes a sample of the negative instances to train on\n",
    "    neg = neg.sample(frac=neg_sample_factor*(n_pos_samples/n_tot_samples)) \n",
    "    \n",
    "    if debug:\n",
    "        print(f\"training on {pos.shape[0]} postitive instances\")\n",
    "        print(f\"training on {neg.shape[0]} negative  instances\")\n",
    "    \n",
    "    df = pd.concat([pos, neg])\n",
    "    X_train = pd.DataFrame(df.text.tolist(), index= df.index)\n",
    "    y_train = df[\"label\"]\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"training on {X_train.shape[0]} instances\")\n",
    "    \n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    if debug:\n",
    "        y_train_pred = clf.predict(X_train) \n",
    "        acc = accuracy_score(y_train, y_train_pred) \n",
    "        f1  = f1_score(y_train, y_train_pred)\n",
    "        print(f\"Accuracy: {acc}\")\n",
    "        print(f\"f1 score: {f1}\")\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cd1e05",
   "metadata": {},
   "source": [
    "**Model Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ee714b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(author: int, df:pd.DataFrame):\n",
    "    # take copy and prepare label\n",
    "    df = df.copy(deep=True)\n",
    "    df[\"label\"] = df[\"target authors\"].apply(lambda x: 1 if author in x else 0)\n",
    "    X = df.drop([\"label\", \"target authors\"], axis=1)\n",
    "    y = df[\"label\"]\n",
    "    # split training and validation - we have fixed random state for reproducability\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "    \n",
    "    # fit to model\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # validatite model\n",
    "    y_pred = clf.predict(X_val)\n",
    "    f1 = f1_score(y_pred, y_val)\n",
    "    presicion = precision_score(y_pred, y_val)\n",
    "    recall = recall_score(y_pred, y_val)\n",
    "    return f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "507b0001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_to_csv(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    As we are building 100 classifiers, printing f1 scores within a notebook is impractical. \n",
    "    following function writes results to csv. \n",
    "    \"\"\"\n",
    "    \n",
    "    with open(\"Model 1 validation.csv\", mode='w') as f:    \n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        header = ['Author Id','F1 score']\n",
    "        writer.writerow(header)\n",
    "        \n",
    "        # loop over each author, build classifier and write to output\n",
    "        authors = np.arange(100)\n",
    "        \n",
    "        for author in tqdm(authors):\n",
    "            f1, precision, recall = evaluate_classifier(author, df)\n",
    "            writer.writerow([author, f1, precision, recall])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5e2ef55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 25793 instances\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target authors</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>4990</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4994</th>\n",
       "      <th>4995</th>\n",
       "      <th>4996</th>\n",
       "      <th>4997</th>\n",
       "      <th>4998</th>\n",
       "      <th>4999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[42, 36]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[45]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[97]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[44, 2]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  target authors  0  1  2  3  4  5  6  7  8  ...  4990  4991  4992  4993  \\\n",
       "0       [42, 36]  0  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "1           [45]  0  0  0  0  1  0  2  2  0  ...     0     0     0     0   \n",
       "3           [97]  0  0  0  0  0  0  1  1  0  ...     0     0     0     0   \n",
       "4            [2]  0  0  0  0  0  0  1  1  0  ...     0     0     0     0   \n",
       "9        [44, 2]  0  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "\n",
       "   4994  4995  4996  4997  4998  4999  \n",
       "0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0  \n",
       "9     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 5001 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/train.json\"\n",
    "df = load_data_set(path)\n",
    "df = pre_processing(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22cc79ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [07:33<00:00,  4.54s/it]\n"
     ]
    }
   ],
   "source": [
    "validate_to_csv(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07b694b",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3f0a319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 25793 instances\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/train.json\"\n",
    "df = load_data_set(path)\n",
    "df = pre_processing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98046034",
   "metadata": {},
   "outputs": [],
   "source": [
    "author = 42\n",
    "model  = train_classifier(author, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b1d3c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [27:58<00:00, 16.79s/it]  \n"
     ]
    }
   ],
   "source": [
    "authors = np.arange(0, 100)\n",
    "models  = []\n",
    "for i in tqdm(authors):\n",
    "    model = train_classifier(i, df)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497d8381",
   "metadata": {},
   "source": [
    "**Model Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "610fce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(author: int, df: pd.DataFrame, classifier):\n",
    "    # simple function to assess model performance\n",
    "    \n",
    "    # create copy and set up label\n",
    "    df = df.copy(deep=True)\n",
    "    df[\"label\"] = df[\"target authors\"].apply(lambda x: 1 if author in x else 0)\n",
    "    \n",
    "    # split up positive and negative instances so as to ensure a balanced training set \n",
    "    # if we don't do this, we end up with a very imbalanced training set \n",
    "    pos = df[df['label'] == 1] \n",
    "    neg = df[df['label'] == 0]\n",
    "    \n",
    "    # takes a sample of the instances to test on\n",
    "    pos = pos.sample(frac=(1/2))\n",
    "    neg = neg.sample(frac=(1/10))\n",
    "    \n",
    "    # recombine \n",
    "    df = pd.concat([pos, neg])\n",
    "    X_test = pd.DataFrame(df.text.tolist(), index= df.index)\n",
    "    y_test = df[\"label\"]\n",
    "    \n",
    "    # perform predictions \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_pred, y_test) \n",
    "    f1  = f1_score(y_pred, y_test) \n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"f1 score: {f1}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefd6826",
   "metadata": {},
   "source": [
    "**Build Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8206dd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 800 instances\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/test.json\"\n",
    "df_test = load_data_set(path)\n",
    "df_test = pre_processing(df_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4896853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(test_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    function for writing predictions to output file. \n",
    "    WARNING: Deletes predictions.csv if present in working directory\n",
    "    \"\"\"\n",
    "    if os.path.exists(\"predictions.csv\"):\n",
    "        os.remove(\"predictions.csv\")\n",
    "        print(\"removed previous predictions\")\n",
    "    \n",
    "    \n",
    "    with open(\"predictions.csv\", mode='w') as f:    \n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        header = ['Id','Predicted']\n",
    "        writer.writerow(header)\n",
    "        \n",
    "        \n",
    "        X_test = pd.DataFrame(test_df.text.tolist(), index=test_df.index)\n",
    "        n      = X_test.shape[0]\n",
    "        \n",
    "        # loop over each training sample and write to necessary format\n",
    "        for Id in tqdm(range(n)):\n",
    "            x   = np.array(X_test.iloc[Id]).reshape(1, -1)\n",
    "            row = [Id]\n",
    "            authors = []\n",
    "            for author, model in enumerate(models):\n",
    "                if np.array(model.predict(x)).item() == 1:\n",
    "                    authors.append(author)\n",
    "\n",
    "            # to match the output requirement \n",
    "            if len(authors) == 0: row.append(-1)\n",
    "            else: row += authors\n",
    "            \n",
    "            writer.writerow(row)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9c7e5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed previous predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:02<00:00, 279.45it/s]\n"
     ]
    }
   ],
   "source": [
    "make_predictions(df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
