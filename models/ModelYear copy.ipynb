{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NUM_WORDS = 5000\n",
    "NUM_AUTHORS = 21246\n",
    "MAX_LEN = 250\n",
    "RANDOM_STATE = 42069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_set(path: str):\n",
    "    \"\"\"\n",
    "    loads data set located at path and returns as pandas data frame\n",
    "    \"\"\"\n",
    "    with open(path) as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    print(f\"loaded {len(data)} instances\")\n",
    "    data = pd.json_normalize(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 25793 instances\n"
     ]
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>authors</th>\n      <th>year</th>\n      <th>abstract</th>\n      <th>venue</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[42, 13720, 36]</td>\n      <td>9</td>\n      <td>[2455, 1858, 2335, 1543, 1800, 1860, 2000, 286...</td>\n      <td>20</td>\n      <td>[41, 1550, 1563, 1594, 1544, 1919, 1644, 37, 1...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[1359, 15881, 45]</td>\n      <td>15</td>\n      <td>[40, 1542, 1691, 2449, 1535, 3616, 2206, 1904,...</td>\n      <td>2</td>\n      <td>[1731, 47, 11, 57, 4624, 1525, 1535, 47, 11, 3...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[19166, 17763]</td>\n      <td>17</td>\n      <td>[40, 1542, 1691, 2449, 1535, 2610, 1543, 1535,...</td>\n      <td></td>\n      <td>[2085, 1719, 1846, 1745, 2243, 1553, 1606, 159...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[97]</td>\n      <td>10</td>\n      <td>[46, 1624, 1547, 56, 1687, 1644, 6, 7, 3386, 1...</td>\n      <td>4</td>\n      <td>[40, 1733, 1735, 1540, 1655, 46, 1624, 1547, 5...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[19617, 2]</td>\n      <td>10</td>\n      <td>[37, 3709, 3836, 1586, 2151, 1727, 3021, 1860,...</td>\n      <td>9</td>\n      <td>[38, 1592, 2088, 1543, 1574, 1727, 1597, 1813,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "             authors  year                                           abstract  \\\n0    [42, 13720, 36]     9  [2455, 1858, 2335, 1543, 1800, 1860, 2000, 286...   \n1  [1359, 15881, 45]    15  [40, 1542, 1691, 2449, 1535, 3616, 2206, 1904,...   \n2     [19166, 17763]    17  [40, 1542, 1691, 2449, 1535, 2610, 1543, 1535,...   \n3               [97]    10  [46, 1624, 1547, 56, 1687, 1644, 6, 7, 3386, 1...   \n4         [19617, 2]    10  [37, 3709, 3836, 1586, 2151, 1727, 3021, 1860,...   \n\n  venue                                              title  \n0    20  [41, 1550, 1563, 1594, 1544, 1919, 1644, 37, 1...  \n1     2  [1731, 47, 11, 57, 4624, 1525, 1535, 47, 11, 3...  \n2        [2085, 1719, 1846, 1745, 2243, 1553, 1606, 159...  \n3     4  [40, 1733, 1735, 1540, 1655, 46, 1624, 1547, 5...  \n4     9  [38, 1592, 2088, 1543, 1574, 1727, 1597, 1813,...  "
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"train.json\"\n",
    "train = load_data_set(path)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df: pd.DataFrame, train=True, drop_samples=False):\n",
    "    \n",
    "    df = df.copy(deep=True)\n",
    "   \n",
    "    if train:\n",
    "        df[\"target authors\"] = df[\"authors\"].apply(lambda x: filter_authors(x))\n",
    "        df[\"coauthors\"]      = df[\"authors\"].apply(lambda x: filter_authors(x, prolifics=False))\n",
    "        df = df.drop([\"authors\"], axis=1)\n",
    "    \n",
    "    # drops samples containing no prolific authors, Reduces training set by ~60% to 7000 samples\n",
    "    if drop_samples:\n",
    "        df[\"has target\"] = df[\"target authors\"].apply(lambda x: len(x)>0)\n",
    "        df = df[df[\"has target\"] == True]\n",
    "        df = df.drop([\"has target\"], axis=1)\n",
    "        \n",
    "    # text transormation\n",
    "    # we stringify the list of int's to be used as inputs to the TF-IDF vectoriser\n",
    "    df[\"text\"] = df[\"title\"] + df[\"abstract\"]\n",
    "    df[\"str text\"] = df[\"text\"].apply(lambda xs: ''.join(str(x)+' ' for x in xs))\n",
    "    \n",
    "    # preprocessing for venue. We use minmax scaling as a matter of best-practice. \n",
    "    # as we require all rows to have integer values, we give blank venues a dummy value of 465\n",
    "    scalar = MinMaxScaler()\n",
    "    df.loc[df.venue == \"\", \"venue\"] = 465\n",
    "    df[\"venue\"] = scalar.fit_transform(df[\"venue\"].to_numpy().reshape(-1, 1))\n",
    "\n",
    "    # drop\n",
    "    #df = df.drop([\"abstract\", \"title\", \"year\"], axis=1)\n",
    "    df = df.drop([\"abstract\", \"title\"], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_authors(authors: List[int], prolifics=True):\n",
    "    \"\"\"\n",
    "    filters authors between prolific and coauthors\n",
    "    \"\"\"\n",
    "    if prolifics:\n",
    "        prolifics = filter(lambda x: x < 100, authors)\n",
    "        return list(prolifics)\n",
    "    else:\n",
    "        coauthors = filter(lambda x: x>=100, authors)\n",
    "        return list(coauthors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(array([ 123.,   89.,  128.,  177.,  214.,  220.,  254.,  266.,  396.,\n         449.,  489.,  433.,  522.,  561.,  590.,  608., 1283.]),\n array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n        17]),\n <BarContainer object of 17 artists>)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = preprocess(train, train=True, drop_samples=True)\n",
    "df.head()\n",
    "plt.hist(df[\"year\"], bins=np.arange(df[\"year\"].min(), df[\"year\"].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 9, 15, 10, 18, 11,  8,  2, 13,  1, 16,  6,  5, 17, 14,  3, 12,  4,\n        7,  0])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"year\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Preprocessing\n",
    "\n",
    "TF-IDF is a nlp preprocessing method to map text input to a vector of reals. TF-IDF is an improvement upon previous feature engineering that we have performed as it adjusts the value of each word, relative to how freuently it occurs. Stop words such as *the, it, how* have relatively low weightings, so the resulting vector only captures the most *important* words within the input. This (typically) leads to TF-IDF representations outperforming word-count representations for most tasks\n",
    "\n",
    "We use `sklearn`'s feature extraction to automate this process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf   = TfidfVectorizer()\n",
    "vectors = tfidf.fit_transform(df[\"str text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>10</th>\n      <th>100</th>\n      <th>1005</th>\n      <th>1006</th>\n      <th>1007</th>\n      <th>1009</th>\n      <th>101</th>\n      <th>1014</th>\n      <th>1016</th>\n      <th>1022</th>\n      <th>...</th>\n      <th>962</th>\n      <th>965</th>\n      <th>968</th>\n      <th>970</th>\n      <th>973</th>\n      <th>977</th>\n      <th>98</th>\n      <th>980</th>\n      <th>987</th>\n      <th>998</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.090374</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.018773</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.130861</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 3869 columns</p>\n</div>",
      "text/plain": "         10  100  1005  1006  1007  1009  101  1014  1016  1022  ...  962  \\\n0  0.000000  0.0   0.0   0.0   0.0   0.0  0.0   0.0   0.0   0.0  ...  0.0   \n1  0.000000  0.0   0.0   0.0   0.0   0.0  0.0   0.0   0.0   0.0  ...  0.0   \n2  0.090374  0.0   0.0   0.0   0.0   0.0  0.0   0.0   0.0   0.0  ...  0.0   \n3  0.018773  0.0   0.0   0.0   0.0   0.0  0.0   0.0   0.0   0.0  ...  0.0   \n4  0.130861  0.0   0.0   0.0   0.0   0.0  0.0   0.0   0.0   0.0  ...  0.0   \n\n   965  968  970  973  977   98  980  987  998  \n0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n\n[5 rows x 3869 columns]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = tfidf.get_feature_names_out()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df_text = pd.DataFrame(denselist, columns=feature_names)\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>10</th>\n      <th>100</th>\n      <th>1005</th>\n      <th>1006</th>\n      <th>1007</th>\n      <th>1009</th>\n      <th>101</th>\n      <th>1014</th>\n      <th>1016</th>\n      <th>1022</th>\n      <th>...</th>\n      <th>973</th>\n      <th>977</th>\n      <th>98</th>\n      <th>980</th>\n      <th>987</th>\n      <th>998</th>\n      <th>target authors</th>\n      <th>venue</th>\n      <th>coauthors</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[42, 36]</td>\n      <td>0.043011</td>\n      <td>[13720]</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[45]</td>\n      <td>0.004301</td>\n      <td>[1359, 15881]</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.090374</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[97]</td>\n      <td>0.008602</td>\n      <td>[]</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.018773</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[2]</td>\n      <td>0.019355</td>\n      <td>[19617]</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.130861</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[44, 2]</td>\n      <td>0.000000</td>\n      <td>[9641, 5623]</td>\n      <td>18</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 3873 columns</p>\n</div>",
      "text/plain": "         10  100  1005  1006  1007  1009  101  1014  1016  1022  ...  973  \\\n0  0.000000  0.0   0.0   0.0   0.0   0.0  0.0   0.0   0.0   0.0  ...  0.0   \n1  0.000000  0.0   0.0   0.0   0.0   0.0  0.0   0.0   0.0   0.0  ...  0.0   \n2  0.090374  0.0   0.0   0.0   0.0   0.0  0.0   0.0   0.0   0.0  ...  0.0   \n3  0.018773  0.0   0.0   0.0   0.0   0.0  0.0   0.0   0.0   0.0  ...  0.0   \n4  0.130861  0.0   0.0   0.0   0.0   0.0  0.0   0.0   0.0   0.0  ...  0.0   \n\n   977   98  980  987  998  target authors     venue      coauthors  year  \n0  0.0  0.0  0.0  0.0  0.0        [42, 36]  0.043011        [13720]     9  \n1  0.0  0.0  0.0  0.0  0.0            [45]  0.004301  [1359, 15881]    15  \n2  0.0  0.0  0.0  0.0  0.0            [97]  0.008602             []    10  \n3  0.0  0.0  0.0  0.0  0.0             [2]  0.019355        [19617]    10  \n4  0.0  0.0  0.0  0.0  0.0         [44, 2]  0.000000   [9641, 5623]    18  \n\n[5 rows x 3873 columns]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_auth_venue = df[[\"target authors\", \"venue\", \"coauthors\", \"year\"]]\n",
    "df_full       = pd.concat([df_text.reset_index(drop=True), df_auth_venue.reset_index(drop=True)], axis=1)\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author Preprocessing\n",
    "\n",
    "We previously used a binning strategy of dealing with coauthors. This time, we instead use a simple count of how many coauthors (with `id>100`) they have previously colaborated with appear in the paper. To do this, we build a dictionary of lists of coauthors for each prolific author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_collaborator_dictionary(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Constructs a database of collobaroter for given author id key. \n",
    "    \"\"\"\n",
    "    \n",
    "    collaboraters = {}\n",
    "    authors       = np.arange(100)\n",
    "    \n",
    "    for author in authors:\n",
    "        df_auth = df.copy(deep=True)\n",
    "        df_auth[\"label\"] = df_auth[\"target authors\"].apply(lambda x: 1 if author in x else 0)\n",
    "        df_auth = df_auth[df_auth[\"label\"] == 1]\n",
    "        coauths = list(set(df_auth[\"coauthors\"].sum()))\n",
    "        collaboraters[author] = coauths\n",
    "    \n",
    "    return collaboraters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "collaborator_db = construct_collaborator_dictionary(df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation\n",
    "\n",
    "We now build and validate a model. We use a `RANDOM_STATE` seed to ensure we generate the same training/evaluation split. We write our results to a csv file to avoid an unecessarily long notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_training(X_train, y_train):\n",
    "    \"\"\"\n",
    "    upsamples the minority class until class balance is achieved\n",
    "    \"\"\"\n",
    "    X = pd.concat([X_train, y_train], axis=1)\n",
    "    \n",
    "    \n",
    "    pos = X[X[\"label\"] == 1]\n",
    "    neg = X[X[\"label\"] == 0]\n",
    "    \n",
    "    pos_upsample = resample(pos, replace=True, n_samples=len(neg), random_state=RANDOM_STATE)\n",
    "    \n",
    "    resampled = pd.concat([neg, pos_upsample])\n",
    "\n",
    "    y_train = resampled[\"label\"]\n",
    "    X_train = resampled.drop([\"label\"], axis=1)\n",
    "    return X_train, y_train\n",
    "\n",
    "\n",
    "def resample_training(X_train, y_train):\n",
    "    \"\"\"\n",
    "    resamples class imbalance using SMOTE: \n",
    "    https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html\n",
    "    \"\"\"\n",
    "    sm = SMOTE(random_state=RANDOM_STATE)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_data(author: int, df:pd.DataFrame, restr = False):\n",
    "    # take copy and prepare label\n",
    "    df = df.copy(deep=True)\n",
    "    df[\"label\"] = df[\"target authors\"].apply(lambda x: 1 if author in x else 0)\n",
    "    \n",
    "    # map number of collaborators for this given instance \n",
    "    collabs = collaborator_db[author]\n",
    "    df[\"num collaborators\"] = df[\"coauthors\"].apply(lambda x: len(set(x).intersection(collabs)))\n",
    "    \n",
    "    # drop irrelevant columns\n",
    "    if restr:\n",
    "        df = df.drop(df[(df[\"year\"] < 9) & (df[\"label\"] == 1)].index)\n",
    "\n",
    "    X = df.drop([\"label\", \"target authors\", \"coauthors\", \"year\"], axis=1)\n",
    "    y = df[\"label\"]\n",
    "\n",
    "    #Based on the restr variable index based on year.\n",
    "    #if restr:\n",
    "    #    X = X.loc[X[\"year\"] >= 9]\n",
    "\n",
    "    #X = X.drop([\"year\"], axis=1)\n",
    "    \n",
    "    # split training and validation - we have fixed random state for reproducability\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "    \n",
    "    # upsample to deal with class imbalance\n",
    "    X_train, y_train = upsample_training(X_train, y_train)\n",
    "    \n",
    "    # we convert to numpy arrays for fitting to sklearn models\n",
    "    # the reason for this is that sklearn throws annoying warnings otherwise\n",
    "    return np.array(X_train), np.array(X_val), np.array(y_train), np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_to_csv(df: pd.DataFrame, restr_lst):\n",
    "    \"\"\"\n",
    "    As we are building 100 classifiers, printing f1 scores within a notebook is impractical. \n",
    "    following function writes results to csv. \n",
    "    \"\"\"\n",
    "    author_lst = []\n",
    "    with open(\"validation_restr_year.csv\", mode='w') as f:    \n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        header = ['Author Id','F1 score']\n",
    "        writer.writerow(header)\n",
    "        \n",
    "        # loop over each author, build classifier and write to output\n",
    "        authors = np.arange(100)\n",
    "        \n",
    "        avg = 0\n",
    "        for author in tqdm(authors):\n",
    "\n",
    "            if author in restr_lst:\n",
    "                X_train, X_val, y_train, y_val = get_train_val_data(author, df, True)\n",
    "            elif author not in restr_lst:\n",
    "                X_train, X_val, y_train, y_val = get_train_val_data(author, df, False)\n",
    "            \n",
    "            clf = LogisticRegression()\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred = clf.predict(X_val)\n",
    "            \n",
    "            f1 = f1_score(y_pred, y_val)\n",
    "            avg += f1\n",
    "            writer.writerow([author, f1])\n",
    "            if f1 <= 0.5:\n",
    "                author_lst.append((f1, author))\n",
    "        writer.writerow([\"average\", avg])\n",
    "    author_lst.sort()\n",
    "    return author_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>10</th>\n      <th>100</th>\n      <th>1005</th>\n      <th>1006</th>\n      <th>1007</th>\n      <th>1009</th>\n      <th>101</th>\n      <th>1014</th>\n      <th>1016</th>\n      <th>1022</th>\n      <th>...</th>\n      <th>973</th>\n      <th>977</th>\n      <th>98</th>\n      <th>980</th>\n      <th>987</th>\n      <th>998</th>\n      <th>target authors</th>\n      <th>venue</th>\n      <th>coauthors</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[42, 36]</td>\n      <td>0.043011</td>\n      <td>[13720]</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[45]</td>\n      <td>0.004301</td>\n      <td>[1359, 15881]</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.090374</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[97]</td>\n      <td>0.008602</td>\n      <td>[]</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.018773</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[2]</td>\n      <td>0.019355</td>\n      <td>[19617]</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.130861</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[44, 2]</td>\n      <td>0.000000</td>\n      <td>[9641, 5623]</td>\n      <td>18</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 3873 columns</p>\n</div>",
      "text/plain": "         10  100  1005  1006  1007  1009  101  1014  1016  1022  ...  973  \\\n0  0.000000  0.0   0.0   0.0   0.0   0.0  0.0   0.0   0.0   0.0  ...  0.0   \n1  0.000000  0.0   0.0   0.0   0.0   0.0  0.0   0.0   0.0   0.0  ...  0.0   \n2  0.090374  0.0   0.0   0.0   0.0   0.0  0.0   0.0   0.0   0.0  ...  0.0   \n3  0.018773  0.0   0.0   0.0   0.0   0.0  0.0   0.0   0.0   0.0  ...  0.0   \n4  0.130861  0.0   0.0   0.0   0.0   0.0  0.0   0.0   0.0   0.0  ...  0.0   \n\n   977   98  980  987  998  target authors     venue      coauthors  year  \n0  0.0  0.0  0.0  0.0  0.0        [42, 36]  0.043011        [13720]     9  \n1  0.0  0.0  0.0  0.0  0.0            [45]  0.004301  [1359, 15881]    15  \n2  0.0  0.0  0.0  0.0  0.0            [97]  0.008602             []    10  \n3  0.0  0.0  0.0  0.0  0.0             [2]  0.019355        [19617]    10  \n4  0.0  0.0  0.0  0.0  0.0         [44, 2]  0.000000   [9641, 5623]    18  \n\n[5 rows x 3873 columns]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plt.hist(df_full[\"year\"], bins=np.arange(df[\"year\"].min(), df[\"year\"].max()))\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_function(author, df):\n",
    "    #for item in author_lst:\n",
    "    # take copy and prepare label\n",
    "    df = df.copy(deep=True)\n",
    "    df[\"label\"] = df[\"target authors\"].apply(lambda x: 1 if author in x else 0)\n",
    "    df_val = df[(df[\"label\"] == 1)] \n",
    "    df_plot = df[(df[\"label\"] == 1) & (df[\"year\"] >= 9)] \n",
    "    print(\"length\", len(df_plot))\n",
    "    print(\"length val\", len(df_val))\n",
    "    #Then plot based on those the author is in\n",
    "    plt.hist(df_val[\"year\"], bins=np.arange(df_val[\"year\"].min(), df_val[\"year\"].max()))\n",
    "    #plt.hist(df_plot[\"year\"], bins=np.arange(df_plot[\"year\"].min(), df_plot[\"year\"].max()))\n",
    "    return\n",
    "\n",
    "restr_lst = [71, 18, 28, 86, 62, 3, 81, 51, 34, 6, 20, 99] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_function(restr_lst[0], df_full) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [08:24<00:00,  5.05s/it]\n"
     ]
    }
   ],
   "source": [
    "result = validate_to_csv(df_full, restr_lst)\n",
    "#print(result)\n",
    "#[(0.3333333333333333, 71), (0.34782608695652173, 18), (0.3529411764705882, 28), \n",
    "# (0.3529411764705882, 86), (0.3555555555555555, 62), (0.3846153846153846, 3), \n",
    "# (0.4, 81), (0.4761904761904762, 51), (0.48484848484848486, 34), (0.5, 6), (0.5, 20), (0.5, 99)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author ID 71:\n",
    "#This is a test:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Binary Classifiers\n",
    "\n",
    "We now build the 100 binary classifers, one for each author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [04:50<03:47,  5.42s/it]"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "authors = np.arange(100)\n",
    "\n",
    "for author in tqdm(authors):\n",
    "    X_train, X_val, y_train, y_val = get_train_val_data(author, df_full)#, split=0.1)\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    models.append(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Predictions\n",
    "\n",
    "We now load in our `test.json` set to generate predictions. We first put the training data through the usual preprocessing pipeline and exclude vocabular that was not part of our `tf-idf` training lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"test.json\"\n",
    "df_test = load_data_set(path)\n",
    "df_test = preprocess(df_test, train=False)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this complicated looking lambda simply removes any words that were not part of our preprocessing. \n",
    "# failing to do so, would pass an unseen word to our tf-idf vectoriser and would crash our program\n",
    "tfidf_features  = tfidf.get_feature_names_out()\n",
    "df_test['text'] = df_test['text'].apply(lambda xs: list(filter((lambda x: str(x) in tfidf_features), xs)))\n",
    "df_test[\"text\"] = df_test[\"text\"].apply(lambda xs: ''.join(str(x)+' ' for x in xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now apply the tf-idf transformation to the text component\n",
    "X_test = tfidf.transform(df_test['text'])\n",
    "X_test = pd.DataFrame((X_test.todense().tolist()), columns=tfidf_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now put everything back together\n",
    "test = pd.concat([X_test, df_test[\"venue\"], df_test[\"coauthors\"], df_test[\"year\"]], axis=1)\n",
    "plt.hist(test[\"year\"], bins=np.arange(test[\"year\"].min(), test[\"year\"].max()))\n",
    "#test = test.drop([\"year\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0      19\n1      19\n2      19\n3      19\n4      19\n       ..\n795    19\n796    19\n797    19\n798    19\n799    19\nName: year, Length: 800, dtype: int64"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test[\"year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19]\n"
     ]
    },
    {
     "data": {
      "text/plain": "(array([  0.,   0.,   0.,   0.,   0., 800.,   0.,   0.,   0.,   0.]),\n array([18.5, 18.6, 18.7, 18.8, 18.9, 19. , 19.1, 19.2, 19.3, 19.4, 19.5]),\n <BarContainer object of 10 artists>)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(test[\"year\"].unique())\n",
    "#Just the year 19!\n",
    "plt.hist(test[\"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(test_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    function for writing predictions to output file. \n",
    "    WARNING: Deletes predictions.csv if present in working directory\n",
    "    \"\"\"\n",
    "    if os.path.exists(\"predictions_restr_year.csv\"):\n",
    "        os.remove(\"predictions_restr_year.csv\")\n",
    "        print(\"removed previous predictions\")\n",
    "    \n",
    "    \n",
    "    with open(\"predictions_restr_year.csv\", mode='w') as f:    \n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        header = ['Id','Predict']\n",
    "        writer.writerow(header)\n",
    "        n      = X_test.shape[0]\n",
    "        \n",
    "        # loop over each training sample and write to necessary format\n",
    "        for Id in tqdm(range(n)):\n",
    "            \n",
    "            # we need to keep x as a dataframe for this model so we can apply the collobartor mapping easily\n",
    "            x   = test_df.iloc[Id].to_frame().T\n",
    "            row = [Id]\n",
    "            authors = \"\"\n",
    "            \n",
    "            for author, model in enumerate(models):\n",
    "                # map number of collaborators for this given instance \n",
    "                X = x.copy(deep = True)\n",
    "                collabs = collaborator_db[author]\n",
    "                X[\"num collaborators\"] = X[\"coauthors\"].apply(lambda x: len(set(x).intersection(collabs)))\n",
    "                X = X.drop([\"coauthors\"], axis=1)\n",
    "                X = np.array(X).reshape(1, -1)\n",
    "               \n",
    "                if np.array(model.predict(X)).item() == 1:\n",
    "                    authors += str(author) + \" \"\n",
    "\n",
    "            # to match the output requirement \n",
    "            if len(authors) == 0: row = [Id, -1]\n",
    "            else: row = [Id, authors]\n",
    "            \n",
    "            writer.writerow(row)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|          | 0/800 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed previous predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [03:45<00:00,  3.55it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test = test.drop([\"year\"], axis=1)\n",
    "make_predictions(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}