{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b76023ef",
   "metadata": {},
   "source": [
    "The previous two models have been more *classical* feature-based machine learning models. This newly proposed model takes advantage of the fact that the text encoding is informative, and better addresses the variable input size of the text with an RNN model.\n",
    "\n",
    "The only feature for this models is the text data, which can be ensembled with other feature-based models to capture the information lost from dropping coauthors and venue. \n",
    "\n",
    "We also (finally) get around to properly performing training, validatation splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4bd2d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List\n",
    "from rnn import RNN\n",
    "\n",
    "RANDOM_STATE = 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "464bf489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_set(path: str):\n",
    "    \"\"\"\n",
    "    loads data set located at path and returns as pandas data frame\n",
    "    \"\"\"\n",
    "    with open(path) as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    print(f\"loaded {len(data)} instances\")\n",
    "    data = pd.json_normalize(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec0ed802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df: pd.DataFrame, train=True):\n",
    "    if train:\n",
    "        df[\"target authors\"] = df[\"authors\"].apply(lambda x: filter_authors(x))\n",
    "        df[\"coauthors\"]      = df[\"authors\"].apply(lambda x: filter_authors(x, prolifics=False))\n",
    "        df[\"has target\"]     = df[\"target authors\"].apply(lambda x: len(x)>0)\n",
    "        df = df[df[\"has target\"] == True]\n",
    "        df = df.drop([\"authors\", \"has target\"], axis=1)\n",
    "\n",
    "   \n",
    "    df[\"text\"] = df[\"title\"] + df[\"abstract\"]\n",
    "    df = df.drop([\"year\", \"abstract\", \"title\", \"venue\", \"coauthors\"], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d6e1b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature transformation\n",
    "\n",
    "def filter_authors(authors: List[int], prolifics=True):\n",
    "    \"\"\"\n",
    "    filters authors between prolific and coauthors\n",
    "    \"\"\"\n",
    "    if prolifics:\n",
    "        prolifics = filter(lambda x: x < 100, authors)\n",
    "        return list(prolifics)\n",
    "    else:\n",
    "        coauthors = filter(lambda x: x>=100, authors)\n",
    "        return list(coauthors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67d60a9",
   "metadata": {},
   "source": [
    "**Training - Validation Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31f373c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_data(author: int, df: pd.DataFrame, random_state=RANDOM_STATE):\n",
    "    \"\"\"\n",
    "    performs the training - validation split for a given author i.\n",
    "    \n",
    "    WARNING: \n",
    "    sklearn ensures that there are positive and negative instances in both sets. \n",
    "    However, there is still a massive class imbalance. We may need to address this \n",
    "    by manually splitting and sampling manually so as to reduce the number of \n",
    "    negative instances\n",
    "    \"\"\"\n",
    "    df[\"label\"] = df[\"target authors\"].apply(lambda x: 1 if author in x else 0)\n",
    "    X = df.drop([\"label\"], axis=1)\n",
    "    y = df[\"label\"]\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7c2b4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 25793 instances\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/train.json\"\n",
    "df = load_data_set(path)\n",
    "df = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "666eab6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target authors</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[42, 36]</td>\n",
       "      <td>[41, 1550, 1563, 1594, 1544, 1919, 1644, 37, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[45]</td>\n",
       "      <td>[1731, 47, 11, 57, 4624, 1525, 1535, 47, 11, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[97]</td>\n",
       "      <td>[40, 1733, 1735, 1540, 1655, 46, 1624, 1547, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2]</td>\n",
       "      <td>[38, 1592, 2088, 1543, 1574, 1727, 1597, 1813,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[44, 2]</td>\n",
       "      <td>[1560, 1694, 11, 1546, 11, 3066, 1728, 47, 160...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target authors                                               text\n",
       "0       [42, 36]  [41, 1550, 1563, 1594, 1544, 1919, 1644, 37, 1...\n",
       "1           [45]  [1731, 47, 11, 57, 4624, 1525, 1535, 47, 11, 3...\n",
       "3           [97]  [40, 1733, 1735, 1540, 1655, 46, 1624, 1547, 5...\n",
       "4            [2]  [38, 1592, 2088, 1543, 1574, 1727, 1597, 1813,...\n",
       "9        [44, 2]  [1560, 1694, 11, 1546, 11, 3066, 1728, 47, 160..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3afc4b0",
   "metadata": {},
   "source": [
    "**Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936a4611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(author: int, df:pd.DataFrame):\n",
    "    \n",
    "    # split training and validation - we have fixed random state for reproducability\n",
    "    X_train, X_val, y_train, y_val = split_train_data(author, df)\n",
    "    \n",
    "    # fit to model\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # validatite model\n",
    "    y_pred = clf.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_train)\n",
    "    return f1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2da7f790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 190.79it/s]\n"
     ]
    }
   ],
   "source": [
    "authors = np.arange(0,100)\n",
    "for author in tqdm(authors):\n",
    "    X_train, X_val, y_train, y_val = split_train_data(author, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b127d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
