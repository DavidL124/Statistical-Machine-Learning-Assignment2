{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34631de7",
   "metadata": {},
   "source": [
    "The first model builds classifiers for each of the prolific authors with `id` equal to `0,...,99` by using a 'vectorised' representation of the text. \n",
    "\n",
    "This second model builds the feature space further, by using venue as a secondary feature. \n",
    "\n",
    "We also formalise a training / validation split between our data sets.\n",
    "\n",
    "The idea behind this model is to capture the vocabularly of each author, and the resulting high dimensional feature space should result in near-linear separability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cc50a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b604e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_set(path: str):\n",
    "    \"\"\"\n",
    "    loads data set located at path and returns as pandas data frame\n",
    "    \"\"\"\n",
    "    with open(path) as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    print(f\"loaded {len(data)} instances\")\n",
    "    data = pd.json_normalize(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23688c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "\n",
    "def pre_processing(df: pd.DataFrame, train=True):\n",
    "    \"\"\"\n",
    "    performs initial preprocessing to base data frame\n",
    "    \"\"\"\n",
    "    # preprocessing for authors\n",
    "    if train:\n",
    "        df[\"target authors\"] = df[\"authors\"].apply(lambda x: filter_authors(x))\n",
    "        df[\"coauthors\"]      = df[\"authors\"].apply(lambda x: filter_authors(x, prolifics=False))\n",
    "        df = df.drop([\"authors\"], axis=1)\n",
    "    \n",
    "    # preprocessing for text - expend text out over separate columns\n",
    "    df[\"abstract\"] = df[\"abstract\"].apply(lambda x: text_to_vector(x))\n",
    "    df[\"title\"]    = df[\"title\"].apply(lambda x: text_to_vector(x))\n",
    "    df[\"text\"]     = df[\"title\"] + df[\"abstract\"]\n",
    "    text_df = pd.DataFrame(df.text.tolist(), index=df.index)\n",
    "    \n",
    "    # preprocessing for venue. We use minmax scaling as a matter of best-practice. \n",
    "    # as we require all rows to have integer values, we give blank venues a dummy value of 465\n",
    "    scalar = MinMaxScaler()\n",
    "    df.loc[df.venue == \"\", \"venue\"] = 465\n",
    "    df[\"venue\"] = scalar.fit_transform(df[\"venue\"].to_numpy().reshape(-1, 1))\n",
    "    \n",
    "    # prepocessing for coauthors\n",
    "    # we use a discretised binning strategy, with n=10 bins by default. \n",
    "    df[\"coauthors\"] = df[\"coauthors\"].apply(lambda x: build_bins(x, n_bins=10))\n",
    "    coauth_df = pd.DataFrame(df.coauthors.tolist(), index=df.index)\n",
    "    \n",
    "    # dropping irrelivent columns & concat with 5000-column text_df\n",
    "    df = df.drop([\"abstract\", \"title\", \"text\", \"year\", \"coauthors\"], axis=1)\n",
    "    df = pd.concat([df, text_df, coauth_df], axis=1)\n",
    "    \n",
    "    # and drop row identifier if test set\n",
    "    if not train:\n",
    "        df = df.drop([\"identifier\"], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad6e280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature transformations\n",
    "\n",
    "def filter_authors(authors: List[int], prolifics=True):\n",
    "    \"\"\"\n",
    "    filters authors between prolific and coauthors\n",
    "    \"\"\"\n",
    "    if prolifics:\n",
    "        prolifics = filter(lambda x: x < 100, authors)\n",
    "        return list(prolifics)\n",
    "    else:\n",
    "        coauthors = filter(lambda x: x>=100, authors)\n",
    "        return list(coauthors)\n",
    "    \n",
    "    \n",
    "def text_to_vector(text: List[int]):\n",
    "    \"\"\"\n",
    "    Converts text to sparse matrix representation\n",
    "    text: List of integers between 1, 4999\n",
    "    \"\"\"\n",
    "    word_vec = np.zeros(5000, dtype=int)\n",
    "    for word in text:\n",
    "        word_vec[word] += 1\n",
    "    return word_vec\n",
    "\n",
    "\n",
    "def build_bins(coauthors: List[int], n_bins=10):\n",
    "    \"\"\"\n",
    "    takes a list of coauthors and returns 10-column data frame\n",
    "    \n",
    "    This might be some of the uggliest code I have ever written, though\n",
    "    sklearn's discrete bins didn't really give what I wanted\n",
    "    \"\"\"\n",
    "    width = np.ceil(21246/n_bins)\n",
    "    bins  = np.zeros(n_bins)\n",
    "    for author in coauthors:\n",
    "        i = 0\n",
    "        while not (max(0,(i-1))*width <= author <= i*width):\n",
    "            i += 1\n",
    "        bins[i-1] += 1\n",
    "    return bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1b03eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "def train_classifier(author: int, df: pd.DataFrame, debug=False):\n",
    "    \"\"\"\n",
    "    Trains a classifier for author i. Assumes text-vectorisaiton has occured.\n",
    "    \n",
    "    Model Features:\n",
    "    text vectorisation\n",
    "    \"\"\"\n",
    "    # create copy and set up label\n",
    "    df = df.copy(deep=True)\n",
    "    df[\"label\"] = df[\"target authors\"].apply(lambda x: 1 if author in x else 0)\n",
    "    df = df.drop([\"target authors\"], axis=1)\n",
    "    \n",
    "    # split up positive and negative instances so as to ensure a balanced training set \n",
    "    # if we don't do this, we end up with a very imbalanced training set \n",
    "    # however, if we don't include enough negative samples, we tend to \"overclassify\". \n",
    "    # we can tune out performance with the below 'neg sample factor'\n",
    "    \n",
    "    neg_sample_factor = 10\n",
    "    \n",
    "    pos = df[df['label'] == 1] \n",
    "    neg = df[df['label'] == 0]\n",
    "    \n",
    "    n_pos_samples = pos.shape[0]\n",
    "    n_tot_samples = df.shape[0]\n",
    "    \n",
    "    # takes a sample of the negative instances to train on\n",
    "    neg = neg.sample(frac=neg_sample_factor*(n_pos_samples/n_tot_samples)) \n",
    "    \n",
    "    if debug:\n",
    "        print(f\"training on {pos.shape[0]} postitive instances\")\n",
    "        print(f\"training on {neg.shape[0]} negative  instances\")\n",
    "    \n",
    "    df = pd.concat([pos, neg])\n",
    "    X_train = df.loc[:, df.columns != \"label\"]\n",
    "    y_train = df[\"label\"]\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"training on {X_train.shape[0]} instances\")\n",
    "    \n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    if debug:\n",
    "        y_train_pred = clf.predict(X_train) \n",
    "        acc = accuracy_score(y_train, y_train_pred) \n",
    "        f1  = f1_score(y_train, y_train_pred)\n",
    "        print(f\"Accuracy: {acc}\")\n",
    "        print(f\"f1 score: {f1}\")\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc980c5",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3f0a319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 25793 instances\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/train.json\"\n",
    "df = load_data_set(path)\n",
    "df = pre_processing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6fc489e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venue</th>\n",
       "      <th>target authors</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043011</td>\n",
       "      <td>[42, 36]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004301</td>\n",
       "      <td>[45]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008602</td>\n",
       "      <td>[97]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019355</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5012 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      venue target authors  0  1  2  3  4  5  6  7  ...    0    1    2    3  \\\n",
       "0  0.043011       [42, 36]  0  0  0  0  0  0  0  0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.004301           [45]  0  0  0  0  1  0  2  2  ...  1.0  0.0  0.0  0.0   \n",
       "2  1.000000             []  0  0  0  0  0  0  0  0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.008602           [97]  0  0  0  0  0  0  1  1  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.019355            [2]  0  0  0  0  0  0  1  1  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "     4    5    6    7    8    9  \n",
       "0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  1.0  1.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "\n",
       "[5 rows x 5012 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b1d3c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:01<00:00,  3.02s/it]\n"
     ]
    }
   ],
   "source": [
    "authors = np.arange(0, 100)\n",
    "models  = []\n",
    "for i in tqdm(authors):\n",
    "    model = train_classifier(i, df)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497d8381",
   "metadata": {},
   "source": [
    "**Model Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "610fce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(author: int, df: pd.DataFrame, classifier):\n",
    "    # simple function to assess model performance\n",
    "    \n",
    "    # create copy and set up label\n",
    "    df = df.copy(deep=True)\n",
    "    df[\"label\"] = df[\"target authors\"].apply(lambda x: 1 if author in x else 0)\n",
    "    \n",
    "    # split up positive and negative instances so as to ensure a balanced training set \n",
    "    # if we don't do this, we end up with a very imbalanced training set \n",
    "    pos = df[df['label'] == 1] \n",
    "    neg = df[df['label'] == 0]\n",
    "    \n",
    "    # takes a sample of the instances to test on\n",
    "    pos = pos.sample(frac=(1/2))\n",
    "    neg = neg.sample(frac=(1/10))\n",
    "    \n",
    "    # recombine \n",
    "    df = pd.concat([pos, neg])\n",
    "    X_test = pd.DataFrame(df.text.tolist(), index= df.index)\n",
    "    y_test = df[\"label\"]\n",
    "    \n",
    "    # perform predictions \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_pred, y_test) \n",
    "    f1  = f1_score(y_pred, y_test) \n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"f1 score: {f1}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefd6826",
   "metadata": {},
   "source": [
    "**Build Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd854f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 800 instances\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/test.json\"\n",
    "df_test = load_data_set(path)\n",
    "df_test = pre_processing(df_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c903c405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venue</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.479570</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.479570</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015054</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.045161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5011 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      venue  0  1  2  3  4  5  6  7  8  ...    0    1    2    3    4    5  \\\n",
       "0  0.479570  0  0  0  0  0  0  1  1  0  ...  1.0  0.0  1.0  0.0  0.0  1.0   \n",
       "1  0.479570  0  0  0  0  0  0  1  1  0  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.015054  0  0  0  0  0  0  1  1  0  ...  2.0  2.0  0.0  1.0  0.0  0.0   \n",
       "3  0.045161  0  0  0  0  0  0  1  1  0  ...  1.0  0.0  1.0  0.0  0.0  0.0   \n",
       "4  1.000000  0  0  0  0  0  0  0  0  0  ...  0.0  4.0  0.0  1.0  4.0  4.0   \n",
       "\n",
       "     6    7    8    9  \n",
       "0  0.0  1.0  0.0  0.0  \n",
       "1  1.0  0.0  0.0  1.0  \n",
       "2  0.0  0.0  0.0  1.0  \n",
       "3  0.0  1.0  0.0  1.0  \n",
       "4  2.0  4.0  2.0  2.0  \n",
       "\n",
       "[5 rows x 5011 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4896853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(test_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    function for writing predictions to output file. \n",
    "    WARNING: Deletes predictions.csv if present in working directory\n",
    "    \"\"\"\n",
    "    if os.path.exists(\"predictions.csv\"):\n",
    "        os.remove(\"predictions.csv\")\n",
    "        print(\"removed previous predictions\")\n",
    "    \n",
    "    \n",
    "    with open(\"predictions.csv\", mode='w') as f:    \n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        header = ['Id','Predicted']\n",
    "        writer.writerow(header)\n",
    "        \n",
    "        \n",
    "        X_test = test_df\n",
    "        n      = X_test.shape[0]\n",
    "        \n",
    "        # loop over each training sample and write to necessary format\n",
    "        for Id in tqdm(range(n)):\n",
    "            x   = np.array(X_test.iloc[Id]).reshape(1, -1)\n",
    "            row = [Id]\n",
    "            authors = []\n",
    "            for author, model in enumerate(models):\n",
    "                if np.array(model.predict(x)).item() == 1:\n",
    "                    authors.append(author)\n",
    "\n",
    "            # to match the output requirement \n",
    "            if len(authors) == 0: row.append(-1)\n",
    "            else: row += authors\n",
    "            \n",
    "            writer.writerow(row)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9c7e5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 13/800 [00:00<00:06, 122.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed previous predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:05<00:00, 149.94it/s]\n"
     ]
    }
   ],
   "source": [
    "make_predictions(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ef062d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
